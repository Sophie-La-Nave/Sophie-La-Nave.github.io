<img width="1440" alt="Screenshot 2025-05-13 at 8 56 18 PM" src="https://github.com/user-attachments/assets/18afcee6-8f87-4727-ba4f-95994130f939" />---
layout: post
title: "Day 1 - Getting Started"
---

### What I Set Out to Do
I was aiming to complete the entirety of the first course module plus packets and notes. Rather than a problem, the focus of this first section was to introduce to experimental design and basic python to display data sets. I was excited to learn more about Pandas, although it wasn't thoroughly explained. I wanted to figure out the basics of data analysis.

---

### What I Actually Did

I ended up discovering a lot about experimental design and Data Analysis as a subject, much less about the code. At the start, I did all the suplementary packets with examples, but I realized that they were very redundant to the lesson material. They're helpful if they're needed or if the subject is not understood, but otherwise are unnecessary.
Here's a summary of the eight lessons in module 1:
1. Data science is the overlap of computational thinking, business intelegence, and statistics. Defining data science.
2. There are 2 types of data; structured and unstructured. Structured data is well organized and labeled (eg. a spread sheet). Unstructured data is every other type of data (eg. text in a newspaper).
3. Experimental design. When dividing subjects in a study into treatment (T) and control (C), there are different ways to choose groups. Researchers could choose (biased), subjects choose (C and T won't be as similair as possible), researchers choose based on hypothesis (super biased), and randomly dividing groups (wow, I wonder if data science comes into play here!?! - It does). Random grouping works because differences tend to average out in large enough tests groups. If there's a small sample size use "blocking" technique to try to balance out the random differences. Blocking is seperating into two different groups, based on key differences that may influence the study, before randomly dividing each group into 2; half randomly switches groups, half stays.
4. Almost everyone uses python for data analysis because of readability (both human and computer).
<img width="1293" alt="Screenshot 2025-05-13 at 8 56 18 PM" src="https://github.com/user-attachments/assets/1cd74814-4352-4891-baab-1b79f2e8a0c3" />
5. Row selection w/ Data Frames. Same importing of Pandas and a new data set (same way of importing). <img width="1176" alt="Screenshot 2025-05-13 at 9 10 16 PM" src="https://github.com/user-attachments/assets/9b8ba934-e70e-479f-b03e-8c7c1b5a8d83" /> This screenshot shows how to find a specific data type. Just input column name, and say what you want to find from under that column. <img width="1246" alt="Screenshot 2025-05-13 at 9 12 27 PM" src="https://github.com/user-attachments/assets/14de0fa7-c082-4f4f-9716-2807b0bb6077" /> This screenshot shows how by writing n = 5, or any number for that matter, will get you random output however many times you input (value at n).
6. Observational Studies, Confounders, and Stratification. Confounders are differences between control (C) and treatment (T) group. T <- confounder ->response (It looks like T is causing response, but there's another variable to consider).
T -> casual link -> response (Response is not a direct result of the treatment group). Like how carrying lighters around shows a link to lung cancer, but it's actually just the fact that people carrying around lighters are more likely to be smokers. So, smoking is the confounder.
7. Simpson's paradox: Trend appears in different groups of data but dissapears or reverses when groups are combined. Stratification = looking at individual groups. Goes over the importance of stratifying so that you're representing data honestly, because although overall data may appear to favor 1 group over another, if you look at individual data sets, that may no longer be true.
8. Data Frames and Conditionals. They evaluate if statments are True or False, and gives you all the data that matches the condition given. <img width="1236" alt="Screenshot 2025-05-13 at 9 18 43 PM" src="https://github.com/user-attachments/assets/9b23b563-9075-41f6-8a6d-21c3d5d04974" /> This screenshot displays code that gives a conditional statment.
9. Software version control with git. Software version control is just tracking old and new versions of code, from repository to git clone, and reversed too. This will be done using github.

---

### What I Learned or Noticed

My take away from this week is that Data science involves a lot of background knowledge; designing experiments, creating data frames, and most importantly, using python. Luckily, I have these skills.. Somewhat. I'll continue to develop these skills, and am excited for the next steps involving more code!! Also, if you plan on taking this course, given the summaries above and/or watching the course videos if you're lost, you could probably skip a majority of module 1.

### What's Next

Module 2 done by the end of tomorrow.
